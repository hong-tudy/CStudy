세그먼테이션에 대해 아는대로 설명해주세요

**메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)**

- 정답
    - ***최초적합(First fit)*** : 최상단 또는 최하단에서부터  바로 할당하는 방식.
        
        들어갈 수 있는 홀을 찾으면
        
        - 모든 공간을 탐색할 필요가 없으므로 오버헤드 발생 X. 시간적인 측면에서는 제일 효율적인 방식입니다
    - ***최적적합(Best fit)*** : 필요한 메모리 크기 이상인 공간 중에서 하는 방식.
        
        가장 작은 홀에 할당
        
        - 모든 공간을 탐색해야 하기 때문에 오버헤드가 발생하지만 공간적인 측면에서는 제일 효율적입니다.
    - ***최악적합(Worst fit)*** : 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당하는 방식. 가장 널널한 곳에 들어가기 때문에 내부 단편화 발생.
        - 마찬가지로 모든 공간을 탐색해야 하니 오버헤드도 발생하고 공간적인 측면에서도 제일 비효율적..
    
    *세 가지 방식 모두 내부 단편화가 발생할 여지가 있으나, 최적적합이 가장 내부단편화가 작게 발생하고 그 다음으로 최초 적합, 그 다음으로 최악 적합이 내부 단편화가 크게 발생할 여지가 있습니다.*
    
- 꼬리질문
    - worst-fit 은 언제 사용할 수 있을까요?
        - 실제로는 잘 사용하지 않지만, 큰 프로세스가 자주 메모리에 올라갔다가 내려가는걸 반복하는 경우 큰 프로세스가 즉각적으로 적재될 수 있는 큰 공간에서부터 적재하는 worst-fit을 사용할 수도 있을거 같습니다.
    - 성능이 가장 좋은 알고리즘은 무엇일까요?
        - 페이지 폴트가 가장 안일어나는 알고리즘
        - first fit best fit이 많이 쓰인다
        - First Fit
            - 장점 : 빠른 할당, 간단한 구현, 탐색 시간 단축
            - 단점 : 단편화, 메모리 효율성 낮음
        - Best Fit
            - 장점 : 메모리 효율성 증가, 단편화 감소
            - 단점 : 구현이 어려움, 탐색시간때문에 속도 저하

**캐시의 지역성에 대해 설명해주세요.**

- 정답
    
    캐시 메모리는 CPU의 처리 속도와 메모리의 속도 차이로 인한 병목현상을 완화하기 위해 사용하는 고속 버퍼 메모리입니다. 주기억장치에 있는 데이터를 액세스하는 데 시간이 오래 걸리므로, 이를 줄이기 위해 자주 사용되는 데이터를 캐시 메모리에 불러와 빠르게 액세스할 수 있도록 합니다. 이렇게 하면 주기억장치와 CPU 간 신호 교환에 이용되는 메모리 대역폭을 I/O 사용에 집중할 수 있게 됩니다.
    
    캐시 메모리는 적중률(Hit rate)을 극대화하기 위해 데이터 지역성(Locality)의 원리를 사용합니다. 지역성은 프로그램이 모든 코드나 데이터를 균등하게 액세스하지 않고, 특정 부분을 집중적으로 참조하는 특성을 의미합니다. 데이터 지역성은 크게 시간적 지역성(Temporal Locality), 공간적 지역성(Spatial Locality), 순차적 지역성(Sequential Locality)으로 나뉩니다:
    
    1. **시간적 지역성(Temporal Locality)**: 한 번 참조한 데이터는 다시 참조할 가능성이 높습니다.
    2. **공간적 지역성(Spatial Locality)**: 참조한 데이터와 인접한 데이터 역시 참조될 가능성이 높습니다.
    3. **순차적 지역성(Sequential Locality)**: 분기가 발생하지 않는 한 명령어는 메모리에 저장된 순서대로 인출/실행됩니다.
    
    캐시 메모리의 성능은 적중률에 의해 결정됩니다. CPU가 메모리에 접근하기 전 먼저 캐시 메모리에서 원하는 데이터의 존재 여부를 확인하는데, 필요한 데이터가 있는 경우를 적중(hit), 없는 경우를 실패(miss)라고 합니다. 요청한 데이터를 캐시 메모리에서 찾을 확률인 적중률(hit rate)이 높을수록 캐시 메모리의 성능이 좋습니다. 지역성은 경향에 불과하므로 항상 높은 적중률을 보장하지는 않습니다.
    

[**페이징과 세그멘테이션에 대해 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%ED%-E%--%EC%-D%B-%EC%A-%--%EA%B-%BC%--%EC%--%B-%EA%B-%B-%EB%A-%--%ED%--%-C%EC%-D%B-%EC%--%--%EC%--%--%--%EB%-C%--%ED%--%B-%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    페이징은 일정한 크기로 프로세스를 자른다
    
    세그멘테이션은 논리적인 세그먼트 단위로 자른다(코드, 데이터, 힙, 스택 등)
    
    - 세그멘테이션은 외부 단편화 위험이 있고 내부 단편화 위험은 없다
    - 세그먼트 테이블을 통해 가상 메모리를 구현한다
    - 세그먼트 테이블은 페이지 테이블에 비해 크기가 작다
    - 가상 주소는 세그먼트 번호와 오프셋으로 구성되어있다

[**내부단편화와 외부단편화가 무엇인지 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%EA%B-%B-%EB%A-%--%EB%-B%A-%EB%A-%B-%-C%--%EB%--%B-%EB%B-%--%EB%-B%A-%ED%-E%B-%ED%--%--%EC%--%--%--%EC%--%B-%EB%B-%--%EB%-B%A-%ED%-E%B-%ED%--%--%EA%B-%--%--%EB%AC%B-%EC%--%--%EC%-D%B-%EC%A-%--%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    외부 단편화란 연속적인 메모리 할당 과정에서 생기는 문제로 프로세스들이 스와핑되는 과정에서 프로세스 사이의 빈 공간이 생기는 것을 말합니다. 이에 전체 잔여 메모리가 충분함에도 새 프로세스가 적재되지 못하는 현상이 생깁니다. 
    
    내부 단편화란 페이지 크기가 프로세스 크기와 딱 나누어떨어지지 않을 때 마지막 페이지에서 생기는 잔여 공간을 말합니다. 예를 들어 208KB의 프로세스가 있고 페이지 크기가 10KB라면 2KB의 잔여 공간이 마지막 페이지에서 생깁니다. 
    

[**요구 페이징(Demand Paging)이 무엇인지 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%EC%-A%--%EA%B-%AC%--%ED%-E%--%EC%-D%B-%EC%A-%---Demand%--Paging-%EC%-D%B-%--%EB%AC%B-%EC%--%--%EC%-D%B-%EC%A-%--%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    프로세스를 메모리에 적재할 때 필요한 페이지만을 메모리에 적재하는 기법입니다
    
    1. CPU가 특정 페이지에 접근하는 명령어 실행
    2. 해당 페이지가 현재 메모리에 있을 경우(유효 비트가 1인 경우) 프레임에 접근
    3. 메모리에 없는경우(유효 비트 0) 페이지 폴트 발생
    4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리에 적재하고 유효 비트 1로 설정
    5. 1번 수행
    
    **순수 요구 페이징(pure demand paging) :** 아무런 페이지도 메모리에 적재하기 않고 실행하는 경우도 있음. 페이지 폴트 초반에 많이 발생 → 점점 빈도 감소
    

[**페이지 교체가 언제 발생하는지, 어떤 교체 알고리즘이 있는지 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%ED%-E%--%EC%-D%B-%EC%A-%--%--%EA%B-%--%EC%B-%B-%EA%B-%--%--%EC%--%B-%EC%A-%-C%--%EB%B-%-C%EC%--%-D%ED%--%--%EB%-A%--%EC%A-%--%-C%--%EC%--%B-%EB%--%A-%--%EA%B-%--%EC%B-%B-%--%EC%--%-C%EA%B-%A-%EB%A-%AC%EC%A-%--%EC%-D%B-%--%EC%-E%--%EB%-A%--%EC%A-%--%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    페이지 폴트발생했을 때 보조 기억장치에 있는 페이지를 메모리로 적재하는 것
    
    - FIFO
    - 2차 기회 페이지 교체 알고리즘
    - 최적 페이지교체 알고리즘
    - LRU

[**Thrashing(쓰레싱)에 대해 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--Thrashing-%EC%--%B-%EB%A-%--%EC%-B%B--%EC%--%--%--%EB%-C%--%ED%--%B-%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    쓰레싱(Thrashing)은 컴퓨터 시스템에서 발생하는 현상으로, 메모리 부족 상태에서 CPU가 대부분의 시간을 페이지 교체 작업에 사용하게 되어 실질적인 작업 처리가 지연되거나 불가능해지는 현상을 말합니다. 이는 여러 프로세스가 동시에 많은 페이지 폴트를 발생시킬 때 발생하며, 적절한 메모리 관리와 페이지 교체 전략이 필요합니다.
    

[**메모리가 고갈되면 일어나는 현상에 대해 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%EB%A-%--%EB%AA%A-%EB%A-%AC%EA%B-%--%--%EA%B-%A-%EA%B-%--%EB%--%--%EB%A-%B-%--%EC%-D%BC%EC%--%B-%EB%--%--%EB%-A%--%--%ED%--%--%EC%--%--%EC%--%--%--%EB%-C%--%ED%--%B-%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    
    메모리가 고갈되면 컴퓨터 시스템에서 여러 문제가 발생할 수 있습니다. 주로 메모리 부족 상태에서는 다음과 같은 현상들이 나타날 수 있습니다:
    
    첫째, **프로세스 실행 지연**: 메모리가 부족하면 프로세스가 실행되기 위해 필요한 데이터나 코드를 메모리에 적재하는 데 시간이 오래 걸리거나 전혀 실행되지 않을 수 있습니다. 이는 응용 프로그램의 반응성을 저하시키고 사용자 경험을 나빠지게 할 수 있습니다.
    
    둘째, **페이지 폴트 증가**: 페이지 폴트는 메모리에서 필요한 페이지가 없어 디스크에서 읽어오는 현상을 말합니다. 메모리가 부족할수록 페이지 폴트가 증가하며, 이는 프로세스의 성능을 저하시키고 CPU 자원을 낭비할 수 있습니다.
    
    셋째, **쓰레싱(Thrashing)**: 쓰레싱은 메모리 부족 상태에서 CPU가 대부분의 시간을 페이지 교체 작업에 소모하게 되어 실질적인 작업 처리가 지연되거나 불가능해지는 현상입니다. 이는 여러 프로세스가 동시에 많은 페이지 폴트를 발생시킬 때 발생할 수 있습니다.
    
    넷째, **응용 프로그램 충돌**: 메모리가 고갈되면 운영 체제는 다양한 프로세스나 서비스들 사이에서 메모리 자원을 효율적으로 분배하기 어려워집니다. 이로 인해 응용 프로그램이 비정상적으로 종료되거나 충돌할 수 있습니다.
    
    이와 같은 문제들은 메모리 관리의 중요성을 강조하며, 적절한 메모리 할당 및 관리 전략을 통해 최소화할 수 있습니다. 메모리가 고갈되지 않도록 사전에 충분한 자원을 할당하거나, 효율적인 메모리 관리 기법을 사용하는 것이 필요합니다.
    

[**메모리 할당 중, 연속(Contiguous) 방식과 불연속(Non-Contiguous) 방식에 대해 설명해주세요.**](https://hoons-dev.tistory.com/95#%F-%-F%--%A-%--%EB%A-%--%EB%AA%A-%EB%A-%AC%--%ED%--%A-%EB%-B%B-%--%EC%A-%--%-C%--%EC%--%B-%EC%--%-D-Contiguous-%--%EB%B-%A-%EC%-B%-D%EA%B-%BC%--%EB%B-%--%EC%--%B-%EC%--%-D-Non-Contiguous-%--%EB%B-%A-%EC%-B%-D%EC%--%--%--%EB%-C%--%ED%--%B-%--%EC%--%A-%EB%AA%--%ED%--%B-%EC%A-%BC%EC%--%B-%EC%-A%---)

- 정답
    - 연속 : 프로세스가 필요한 모든 메모리가 연속된 하나의 메모리블록에 할당되는 방식입니다
        - 간단하고 빠른 주소 접근이 가능하지만, 단편화 문제와 유연성 부족
    - 불연속 : 프로세스가 필요한 메모리를 여러 개의 불연속된 메모리 블록에 나누어 할당하는 방식입니다.
        - 메모리 사용의 유연성과 효율성을 제공하지만, 주소 변환의 복잡성과 추가적인 메모리 오버헤드가 발생

가상 메모리에 대해 설명해보세요

- 정답
    
    가상 메모리는 프로세스가 실제 메모리의 크기와 상관없이 메모리를 사용할 수 있도록 지원하는 기술입니다. 가상 메모리는 실제 메모리(RAM, 메인 메모리)와 보조 기억 장치(보조 저장소)의 스왑 영역으로 구성됩니다. 운영체제는 메모리 관리자(Memory Management Unit, MMU)를 통해 메모리를 관리하며, 프로세스는 자신이 사용하는 메모리가 실제 메모리인지 스왑 영역인지 알지 못합니다.
    
    Java에서는 스왑 영역을 사용하지 않도록 설정한 경우 OutOfMemoryError(OOM)가 발생할 수 있습니다. 스왑 영역은 실제 메모리가 아니기 때문에 접근 시 지연 시간이 많이 발생하므로, 가급적 스왑 메모리를 사용하지 않도록 설계하는 것이 좋습니다. 만약 스왑 메모리 사용량이 계속 증가한다면 메모리 누수를 의심해 볼 수 있습니다.
    

가상 메모리 페이징 시스템에 대해 구체적으로 설명해주세요

- 정답
    
    가상 메모리 페이징 시스템은 컴퓨터 시스템에서 물리적 메모리와 가상 메모리를 효율적으로 관리하기 위한 메모리 관리 기법입니다. 이 시스템을 사용하면 프로그램은 실제 물리적 메모리보다 더 많은 메모리를 사용할 수 있으며, 이를 통해 메모리 사용의 유연성과 효율성을 높일 수 있습니다.
    

요구 페이징과 페이지 폴트에 대해 구체적으로 설명해주세요

- 정답
    
    요구 페이징은 프로세스에 모든 데이터를 메모리에 적재하지 않고, 실행 중 필요한 시점에만 메모리에 적재하는 페이징 기법이다. 페이지 폴트는 어떤 페이지가 실제 물리 메모리에 없을 때 일어나는 인터럽트로 운영체제는 페이지 폴트가 발생하면 해당 페이지를 물리 메모에 올린다.
    

MMU와 TLB에 대해 구체적으로 설명해주세요

- 정답
    
    CPU는 가상 주소 접근 시 MMU 하드웨어 장치를 통해 물리 메모리로 접근한다. (MMU가 페이지 테이블 base 주소를 접근해서, 물리 주소를 가져온다.)
    

세그멘테이션과 페이징의 차이점

- 정답
    - segmentation 은 프로그램을 의미 단위인 여러개의 segment 로 나눈다.
        - page 와 다르게 각 segment 의 크기는 같지 않다.
        - 따라서 물리 메모리상에 fragmentation 이 생길 수 있다.
    - segmentation 은 의미 단위로 프로그램을 쪼개기 때문에 protection 설정과 sharing 설정이 쉽다.
        - page는 크기가 동일하여 설정이 애매한 경우가 있다.
    - segmentation 의 segment table 은 일반적으로 page table 보다 작다.
        - 각 프로세스당 segment 개수는 그렇게 많지 않다.

**가상 메모리란 무엇인가요?**

- 정답
    
    가상 메모리는 메모리가 실제 메모리보다 많아 보이게하는 기술로, 어떤 프로세스가 실행될 때 전체가 메모리에 올라가지 않더라도 실행이 가능하다는 점을 착안하여 고안한 기술입니다.
    
    메인 메모리와 디스크의 페이징 스페이스를 묶어 하나의 메모리처럼 동작하게 하여 구현합니다.
    

가상 메모리가 가능한 이유가 무엇일까요?

- 정답
    
    메모리 시스템에서는 ****각 프로세스가 완전히 동일한 포맷의 가상 주소 공간을 가진다. ****실제로 메모리 참조를 수행할 때는 가상 주소를 물리 주소로 변환하는 작업이 진행되기 때문.각각의 프로세스에게 혼자 메인 메모리를 사용한다는듯한 착각을 제공
    

Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.

- 정답
    
    프로세스가 실제 물리 메모리에 올라와 있지 않은 페이지에 접근하려고 할 때 발생하는 상황을 페이지 폴트라고 합니다. 페이지 폹트가 발생하면 메모리에 비어있는 프레임이 있다면 해당 페이지에 메모리를 적재하고 만약 비어있는 프레임이 없다면 희생 프레임을 골라 스왑아웃하고 메모리에 적재합니다.
    

페이지 크기에 대한 Trade-Off를 설명해 주세요.

- 정답
    
    페이지가 크면 내부 단편화 발생
    
    페이지가 작으면 페이지 테이블 크기 증가
    

페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?

- 정답
    
    페이지 크기가 커지면 페이지 폴트 발생률은 낮아집니다. 하지만 내부 단편화의 위험이 커지기 때문에 메모리 낭비가 발생합니다.
    

세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?

- 정답
    
    세그멘테이션 방식을 사용하면 각 세그먼트가 독립적으로 크기를 가질 수 있어 메모리 사용의 효율성을 높일 수 있습니다. 필요한 세그먼트만 메모리에 적재하고, 나머지는 디스크에 보관할 수 있습니다.
    
    각 세그먼트는 세그먼트 테이블에 의해 관리되며, 이 테이블은 세그먼트의 시작 주소와 크기 정보를 포함합니다. 가상 주소는 세그먼트 번호와 오프셋으로 구성되며, 이를 통해 물리적 주소로 변환됩니다.
    

페이지와 프레임의 차이에 대해 설명해 주세요.

- 정답
    
    페이지는 고정 사이즈의 가상 메모리 내의 프로세스 조각을 말하고, 프레임은 페이지와 크기가 같은 주기억장치의 메모리 조각을 말합니다.
    

페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.

- 정답
    
    모든 프로세스는 하나의 페이징 테이블을 가지고 있고 여기에는 메인 메모리에 적재되어 있는 페이지 번호와 해당 페이지가 위치한 메인 메모리의 시작 주소가 있습니다. 가상 주소는 페이지 번호와 페이지 오프셋으로 되어있는데 페이지 번호를 통해 페이지 테이블에서 프레임의 베이스 주소를 알아냅니다.
    

어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?

- 정답
    
    페이지 테이블 엔트리의 보호 비트를 통해 알 수 있다. 읽고 쓰기가 모두 가능하다면 1, 읽기 전용이라면 0으로 표현한다. r, w, x 등으로 표현해, w 를 통해 쓰기 작업이 가능한지 확인할 수 있다. 
    

32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?

- 정답
    
    ![Screenshot 2024-07-18 at 3.52.00 PM.png]([https://prod-files-secure.s3.us-west-2.amazonaws.com/daaf6a75-66ec-4016-bcc8-9527acc8181a/13839522-c085-4271-9814-0b3e7d9b32e1/Screenshot_2024-07-18_at_3.52.00_PM.png](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fdaaf6a75-66ec-4016-bcc8-9527acc8181a%2F13839522-c085-4271-9814-0b3e7d9b32e1%2FScreenshot_2024-07-18_at_3.52.00_PM.png?table=block&id=a7181dde-a8ed-47cc-b26f-0f4a9bccd4dc&spaceId=daaf6a75-66ec-4016-bcc8-9527acc8181a&width=2000&userId=a36d52bd-98a8-44d6-b470-23b1aa900130&cache=v2))
    

32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.

- 정답
    
    32비트 운영체제에서는 2^32개의 주소를 표현할 수 있으므로 최대 4GB(2^32 바이트)의 메모리 주소 공간을 관리할 수 있습니다. 페이징을 사용하면 이 가상 주소 공간을 물리 메모리와 매핑할 수 있지만, 32비트 주소 체계 자체가 가질 수 있는 주소의 최대 한계로 인해 물리 메모리도 최대 4GB까지만 직접 접근할 수 있습니다. 
    

C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?

- 정답
    
    Segmentation Fault(세그멘테이션 폴트)는 메모리 접근 오류로 인해 발생하는 런타임 에러입니다. C/C++ 개발에서 자주 접하게 되며, 주로 잘못된 메모리 접근, 예를 들어 NULL 포인터 참조, 해제된 메모리 접근, 경계를 벗어난 배열 접근 Read-Only를 쓰려고 할 때 등으로 발생합니다.
    
    세그먼테이션 / 페이징 기법은 메모리를 관리하고 프로세스간 메모리를 격리하여, 유효하지 않은 메모리 접근을 감지하고 시스템의 안정성을 유지하는 데 도움을 줍니다. (페이징 기법 - 보호비트, 세그먼테이션 - ?) 따라서 segmentaion fault 는 세그먼테이션 / 페이징 메커니즘에 의해 보호되는 메모리 모델과 밀접한 관계가 있습니다. 
    
    **◈ segmentation fault의 원인**
    
    1. null 값을 가리키는 포인터에 접근할 경우
    
    2. 할당 받은 메모리 공간을 넘은 곳을 건드린 경우
    
    3. 더 이상 존재하지 않는 메모리 영역을 가리킬 경우
    
    4. read-only 표시 메모리 영역에 쓰려고 할 경우
    

**TLB는 무엇인가요?**

- 정답
    
    TLB(Translation Lookaside Buffer)는 가상 메모리 주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용하는 고속 캐시입니다. CPU가 가상 주소로 메모리에 접근할 때, TLB를 먼저 확인하여 변환 정보를 찾습니다. 변환 정보가 TLB에 있으면(TLB 히트) 즉시 물리 주소로 접근할 수 있어 속도가 매우 빠릅니다. 변환 정보가 TLB에 없으면(TLB 미스) 페이지 테이블을 조회하여 변환 정보를 찾고 이를 TLB에 저장한 후 물리 주소로 접근합니다. 이를 통해 TLB는 메모리 접근 시간을 최적화하고 시스템 성능을 크게 향상시킵니다.
    

LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요? 

- 시간 지역성의 특성을 활용한 알고리즘입니다. 최근에 사용된 페이지는 앞으로도 자주 사용될 가능성이 높고, 반대로 오랫동안 사용되지 않은 페이지는 앞으로도 사용되지 않을 가능성이 높다는 가정합니다.

LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?

- 정답
    
    ![](https://valueengine.tistory.com/65)
    
    - **연결 리스트**: 이중 연결 리스트를 사용하여 페이지를 삽입할 때마다 리스트의 끝에 추가하고, 참조될 때마다 해당 페이지를 리스트의 끝으로 이동시킵니다.
    - **해시 맵과 더블 링크드 리스트**: 해시 맵을 사용하여 페이지의 위치를 빠르게 찾고, 더블 링크드 리스트를 사용하여 LRU 순서를 유지합니다. 페이지가 참조될 때마다 해당 페이지를 리스트의 끝으로 이동시킵니다.
    - **카운터 기반**: 각 페이지에 시간 스탬프를 저장하고, 페이지가 참조될 때마다 시간 스탬프를 업데이트하여 가장 오래된 시간 스탬프를 가진 페이지를 교체합니다.

LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.

- 정답
    
    ### LRU 알고리즘의 대안
    
    1. **LFU (Least Frequently Used)**: 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘입니다. 시간 지역성이 아닌 사용 빈도에 기반합니다.
    2. **Clock 알고리즘**: LRU와 비슷하지만, 페이지 접근 시마다 참조 비트를 설정하고, 교체할 때는 시계 방향으로 이동하며 참조 비트가 0인 페이지를 교체합니다. LRU보다 오버헤드가 적습니다.
    3. **ARC (Adaptive Replacement Cache)**: LRU와 LFU의 장점을 결합한 알고리즘입니다. 두 개의 LRU 리스트를 사용하여 자주 사용된 페이지와 최근에 사용된 페이지를 모두 고려합니다.

페이지 폴트를 설명해주세요.

- 정답
    
    페이지 폴트는 프로그램이 가상 메모리 내의 페이지에 접근하려고 할 때, 해당 페이지가 현재 물리적 메모리에 존재하지 않는 경우 발생하는 이벤트입니다. 페이지 폴트가 발생하면 운영 체제는 필요한 페이지를 보조기억장치(보통 하드 디스크 또는 SSD)에서 물리적 메모리로 로드하는 과정을 수행합니다.
